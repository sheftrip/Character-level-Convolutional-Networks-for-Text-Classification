{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cleaning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TU2f2fx6At5w",
        "colab_type": "text"
      },
      "source": [
        "**Mounting The Drive**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RxJ_eXgGuCL",
        "colab_type": "code",
        "outputId": "528707e6-75d9-4ccf-9fa3-b9f6f7864a0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndIAND5WBC-Z",
        "colab_type": "text"
      },
      "source": [
        "**Specifying Path:**\n",
        "\n",
        "---\n",
        "\n",
        "DIR is the path to the directory of the unclean dataset as located in the Drive.\n",
        "The unclean dataset is stored as newsSpace."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBaGEDJ-HVx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DIR = '/content/drive/My Drive/OurDataset/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fDSfx6hHbH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "finput = open(DIR + 'newsSpace');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxDzzYsmBlHV",
        "colab_type": "text"
      },
      "source": [
        "**Cleaning the Dataset:**\n",
        "\n",
        "---\n",
        "Steps Followed:\n",
        "\n",
        "\n",
        "1.   Lines ending with a \"\\\" were concatenated to the string clean_txt, after removing said \"\\\", with a space in between, to form a single line.\n",
        "2. Lines ending with neither \"\\N\" nor \"\\\" are simply concatenated into clean_txt.\n",
        "3.   If a line ended with a \"\\N\", it is concatenated with with clean_txt. After which it is subsequently cleaned by:\n",
        "\n",
        "\n",
        "\n",
        "    *   Replacing and removing HTML encodings\n",
        "    *   Removing HTML tags\n",
        "    *   Removing stray \"\\   \\\" and \"\\N\"\n",
        "    *   Removing urls\n",
        "    *   Removing the time format\n",
        "    *   Removing stray numerals\n",
        "\n",
        "4. Data is then split using \"\\t\" as the delimiter.\n",
        "5. Out this split data we obtained the values for class, title and description.\n",
        "6. 30,000 unique titles of each class are extracted to populate train.csv.\n",
        "1900 unique titles of each class are extracted to populate test.csv.\n",
        "As of now they are stored in their respective dictionary data structure.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtLEkULHeVPb",
        "colab_type": "code",
        "outputId": "3de8b173-2701-4adc-f6dc-fa4852ee4e82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "import re\n",
        "\n",
        "txt = finput.readline()\n",
        "clean_txt = \"\"\n",
        "\n",
        "i = 0\n",
        "j = 0\n",
        "\n",
        "business = 0\n",
        "sci = 0\n",
        "world = 0\n",
        "sports = 0\n",
        "\n",
        "uniqueTitles = set()\n",
        "title = list()\n",
        "category = list()\n",
        "description = list()\n",
        "\n",
        "test_title = list()\n",
        "test_category = list()\n",
        "test_description = list()\n",
        "\n",
        "while txt:\n",
        "  # print(txt)\n",
        "  txt = txt.strip()\n",
        "  # if(i > 783262):\n",
        "  #   print(txt[-1])\n",
        "  if len(txt) == 0:\n",
        "    x = 1;\n",
        "  elif txt[-1] == '\\\\':\n",
        "    txt = txt.rstrip('\\\\')\n",
        "    txt = txt.lstrip()\n",
        "    if len(txt) > 0:\n",
        "      clean_txt = clean_txt + \" \" + txt    \n",
        "\n",
        "  elif txt[-1] == 'N' and txt[-2] == '\\\\':\n",
        "    txt = txt.rstrip('\\\\N ') \n",
        "    txt = txt.lstrip()\n",
        "    clean_txt = clean_txt + \" \" +txt\n",
        "    # remove html encodings\n",
        "    clean_txt = re.sub(r\"&#39;\", '\\'', clean_txt)\n",
        "    clean_txt = re.sub(r\"&#36;\", '$', clean_txt)\n",
        "    clean_txt = re.sub(r\"&#37;\", '%', clean_txt)\n",
        "    clean_txt = re.sub(r\"&#\\d+;\", '', clean_txt)\n",
        "    \n",
        "    # remove html tags\n",
        "    clean_txt = re.sub(r\"<b>...</b>\", '', clean_txt)\n",
        "    clean_txt = re.sub(r\"<\\w+>\", '', clean_txt)\n",
        "    clean_txt = re.sub(r\"</\\w+>\", '', clean_txt)\n",
        "    clean_txt = re.sub(r\"<img src.+/>\", '', clean_txt)\n",
        "    clean_txt = re.sub(r\"<a href=\\\"\", '', clean_txt)\n",
        "    clean_txt = re.sub(r\"<br/>\", ' ', clean_txt)\n",
        "    # Remove stray \\  \\ and \\N\n",
        "    clean_txt = re.sub(r\"\\\\\\t\\\\\", '', clean_txt)\n",
        "    clean_txt = re.sub(r\"\\\\N\", '', clean_txt)\n",
        "\n",
        "    # remove url column\n",
        "    clean_txt = re.sub(r\"http\\S+\", '', clean_txt)\n",
        "    clean_txt = re.sub(r\" Globe -- Business News\", '', clean_txt)\n",
        "    clean_txt = re.sub(r\" Globe -- Sports News\", '', clean_txt)\n",
        "    clean_txt = re.sub(r\" Globe -- World News\", '', clean_txt)\n",
        "\n",
        "    # remove time column\n",
        "    clean_txt = clean_txt.rstrip() \n",
        "    clean_txt = re.sub(r\"\\d\\d\\d\\d-\\d\\d-\\d\\d\\s\\d\\d:\\d\\d:\\d\\d\", '', clean_txt)\n",
        "\n",
        "    #remove number column\n",
        "    clean_txt = clean_txt.rstrip('\\t ') \n",
        "    clean_txt = re.sub(r\"\\d$\", '', clean_txt)\n",
        "\n",
        "    #removing all boundary whitespaces\n",
        "    clean_txt = clean_txt.strip() \n",
        "\n",
        "\n",
        "    # if( i < 20):\n",
        "    #   print(clean_txt)\n",
        "    \n",
        "    columns = re.split(r\"\\t+\", clean_txt);\n",
        "\n",
        "    n = len(columns)\n",
        "    \n",
        "    if n >= 4:\n",
        "      if not(columns[1] in uniqueTitles):\n",
        "        m = 4\n",
        "        des = \"\"\n",
        "        while m < n:\n",
        "          if(len(columns[m].strip()) > 0):\n",
        "            des = des + columns[m].strip() + \" \";\n",
        "          m += 1\n",
        "        des.strip('\\t ')\n",
        "\n",
        "        if(columns[3] == 'Business' and business < 31900 and len(des) > 0):\n",
        "          if(business < 30000):\n",
        "            title.append(columns[1].strip())\n",
        "            category.append(3)\n",
        "            description.append(des)\n",
        "          elif(business >= 30000 and business < 31900):\n",
        "            test_title.append(columns[1].strip())\n",
        "            test_category.append(3)\n",
        "            test_description.append(des)\n",
        "\n",
        "          business += 1\n",
        "        elif(columns[3] == 'Sci/Tech' and sci < 31900 and len(des) > 0):\n",
        "          if(sci < 30000):\n",
        "            title.append(columns[1])\n",
        "            category.append(4)\n",
        "            description.append(des)\n",
        "          elif(sci >= 30000 and sci < 31900):\n",
        "            test_title.append(columns[1].strip())\n",
        "            test_category.append(4)\n",
        "            test_description.append(des)\n",
        "          \n",
        "          sci += 1\n",
        "        elif(columns[3] == 'World' and world < 31900 and len(des) > 0):\n",
        "          if(world < 30000):\n",
        "            title.append(columns[1])\n",
        "            category.append(1)\n",
        "            description.append(des)\n",
        "          elif(world >= 30000 and world < 31900):\n",
        "            test_title.append(columns[1].strip())\n",
        "            test_category.append(1)\n",
        "            test_description.append(des)\n",
        "\n",
        "          world += 1;\n",
        "        elif(columns[3] == 'Sports' and sports < 31900 and len(des) > 0):\n",
        "          if(sports < 30000):\n",
        "            title.append(columns[1])\n",
        "            category.append(2)\n",
        "            description.append(des)\n",
        "          elif(sports >= 30000 and sports < 31900):\n",
        "            test_title.append(columns[1].strip())\n",
        "            test_category.append(2)\n",
        "            test_description.append(des)\n",
        "\n",
        "          sports += 1;\n",
        "\n",
        "        uniqueTitles.add(columns[2])\n",
        "\n",
        "\n",
        "\n",
        "    clean_txt = \"\"\n",
        "  else:\n",
        "    clean_txt = clean_txt + txt\n",
        "    \n",
        "  i = i + 1\n",
        "  txt = finput.readline()\n",
        "\n",
        "print(business)\n",
        "print(sci)\n",
        "print(sports)\n",
        "print(world)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31900\n",
            "31900\n",
            "31900\n",
            "31900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MbuhSl7GHCq",
        "colab_type": "text"
      },
      "source": [
        "**Populating the CSV Files:**\n",
        "\n",
        "---\n",
        " Using the pandas library the dictionaries storing test data and train data are converted to DataFrames and then into test.csv and train.csv respectively.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7i1QEMPOmkSX",
        "colab_type": "code",
        "outputId": "5271cb4e-4a6a-4e45-c1e2-7d55cd5d9754",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "traindata = {\n",
        "    'Class' : category,\n",
        "    'Title' : title,\n",
        "    'Description': description\n",
        "} \n",
        "testdata = {\n",
        "    'Class' : test_category,\n",
        "    'Title' : test_title,\n",
        "    'Description': test_description\n",
        "} \n",
        "\n",
        "traindf = pd.DataFrame(traindata)\n",
        "traindf.to_csv(DIR + 'train.csv', header = False, index = False)\n",
        "\n",
        "testdf = pd.DataFrame(testdata)\n",
        "testdf.to_csv(DIR + 'test.csv', header = False, index = False)\n",
        "\n",
        "print(\"Done\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}